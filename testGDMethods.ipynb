{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---------------------------------DATA PREPROCESSING---------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import datasets.data as data\n",
    "from descent_algorithms import *\n",
    "from models import *\n",
    "from util import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "features, labels = data.load_wisconsin_breast_cancer()\n",
    "wbc_X_train, wbc_X_test, wbc_y_train, wbc_y_test = train_test_split(\n",
    "    features, labels, test_size=0.2)\n",
    "\n",
    "cod_features, cod_labels = data.load_cod_rna()\n",
    "cod_X_train, cod_X_test, cod_y_train, cod_y_test = train_test_split(\n",
    "    cod_features, cod_labels, test_size = 0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "rl_conv = 0.0000000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Learning Rate Objects\n",
    "lr = FixedRate(0.00001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(558, 1)\n",
      "Iter:        0 train loss: 5.140\n",
      "Iter:       10 train loss: 0.625\n",
      "Iter:       20 train loss: 0.089\n",
      "Iter:       30 train loss: 0.573\n",
      "Iter:       40 train loss: 0.849\n",
      "Iter:       50 train loss: 0.947\n",
      "Iter:       60 train loss: 0.982\n",
      "Iter:       70 train loss: 0.994\n",
      "Iter:       80 train loss: 0.998\n",
      "Iter:       90 train loss: 0.999\n"
     ]
    }
   ],
   "source": [
    "gd = GradientDescent()\n",
    "\n",
    "#num = 20000\n",
    "#wbc_X_train = wbc_X_train[0:num]\n",
    "#wbc_X_test = wbc_X_test[0:num]\n",
    "#wbc_y_train = wbc_y_train[0:num]\n",
    "#wbc_y_test = wbc_y_test[0:num]\n",
    "print(wbc_y_train.shape)\n",
    "X = np.array([\n",
    "    [-2, -4],\n",
    "    [-4, -1],\n",
    "    [1, 6],\n",
    "    [2, 4],\n",
    "    [6, 2]\n",
    "])\n",
    "\n",
    "y = np.array([-1,-1,1,1,1])\n",
    "y = y.reshape((y.shape[0], 1))\n",
    "\n",
    "wbc_y_train_svm = zero_one_labels_to_signed(wbc_y_train)\n",
    "svm = SVM(gd, FixedRate(0.1), 1, 100, X.shape[0], rl_conv)\n",
    "loss = svm.fit(X, y, non_zero_init = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[4.42689981e-05]\n",
      " [5.01715312e-05]]\n",
      "[[0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]]\n",
      "Model Accuracy: 60.00%\n"
     ]
    }
   ],
   "source": [
    "wbc_y_test_svm = zero_one_labels_to_signed(wbc_y_test)\n",
    "acc = check_accuracy_svm(svm, X, y)\n",
    "print(\"Model Accuracy: {0:.2f}%\".format(acc * 100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.quiver.Quiver at 0x20504418f28>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "for d, sample in enumerate(X):\n",
    "    # Plot the negative samples\n",
    "    if d < 2:\n",
    "        plt.scatter(sample[0], sample[1], s=120, marker='_', linewidths=2)\n",
    "    # Plot the positive samples\n",
    "    else:\n",
    "        plt.scatter(sample[0], sample[1], s=120, marker='+', linewidths=2)\n",
    "\n",
    "# Add our test samples\n",
    "w = svm.w\n",
    "\n",
    "# Print the hyperplane calculated by svm_sgd()\n",
    "x2=[w[0],w[1],-w[1],w[0]]\n",
    "x3=[w[0],w[1],w[1],-w[0]]\n",
    "\n",
    "x2x3 =np.array([x2,x3])\n",
    "X,Y,U,V = zip(*x2x3)\n",
    "ax = plt.gca()\n",
    "ax.quiver(X,Y,U,V,scale=1, color='blue')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Descent Algorithm Objects\n",
    "gd = GradientDescent()\n",
    "gd1 = GradientDescent()\n",
    "gd2 = GradientDescent()\n",
    "# gd = StochasticVarianceReducedGradientDescent()\n",
    "# gd = NesterovAcceleratedDescent()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Models(descent_algo, learning rate, iterations, batch, relative convergence)\n",
    "logreg = LogisticRegression(gd, lr, 25000, wbc_X_train.shape[0], rl_conv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter:        0 train loss: 386.760\n",
      "Iter:     2500 train loss: 364.650\n",
      "Iter:     5000 train loss: 356.702\n",
      "Iter:     7500 train loss: 351.483\n",
      "Iter:    10000 train loss: 346.991\n",
      "Iter:    12500 train loss: 342.818\n",
      "Iter:    15000 train loss: 338.867\n",
      "Iter:    17500 train loss: 335.107\n",
      "Iter:    20000 train loss: 331.523\n",
      "Iter:    22500 train loss: 328.104\n"
     ]
    }
   ],
   "source": [
    "loss = logreg.fit(wbc_X_train, wbc_y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'check_accuracy' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-11-decfe4ccc132>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m#modelAccuracyCheck\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0macc\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcheck_accuracy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlogreg\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mwbc_X_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mwbc_y_test\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Model Accuracy: {0:.2f}%\"\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0macc\u001b[0m \u001b[1;33m*\u001b[0m \u001b[1;36m100\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0macc\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcheck_accuracy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcod_logreg\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcod_X_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcod_y_test\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'check_accuracy' is not defined"
     ]
    }
   ],
   "source": [
    "#modelAccuracyCheck\n",
    "acc = check_accuracy(logreg, wbc_X_test, wbc_y_test)\n",
    "print(\"Model Accuracy: {0:.2f}%\".format(acc * 100))\n",
    "\n",
    "acc = check_accuracy(cod_logreg, cod_X_test, cod_y_test)\n",
    "print(\"Model Accuracy: {0:.2f}%\".format(acc * 100))\n",
    "\n",
    "acc = check_accuracy(MNIST_logreg, MNIST_X_test, MNIST_y_test)\n",
    "print(\"Model Accuracy: {0:.2f}%\".format(acc * 100))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "# plt.figure(200)\n",
    "# plt.title('Training Accuracy')\n",
    "# plt.xlabel('Iteration x10^2')\n",
    "# plt.ylabel('Accuracy')\n",
    "# plt.plot(accuracies, 'b')\n",
    "# plt.show()\n",
    "# plt.figure(300)\n",
    "# plt.title('Validation Accuracy')\n",
    "# plt.xlabel('Iteration x10^2')\n",
    "# plt.ylabel('Accuracy')\n",
    "# plt.plot(val_accuracies, 'b')\n",
    "# plt.show()\n",
    "plt.figure(1, figsize=(12, 6))\n",
    "plt.title('Loss Plot')\n",
    "plt.xlabel('Iteration Number')\n",
    "plt.ylabel('Loss')\n",
    "plt.plot(loss, 'b')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
