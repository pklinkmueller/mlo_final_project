{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---------------------------------DATA PREPROCESSING---------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import datasets.data as data\n",
    "from descent_algorithms import *\n",
    "from models import *\n",
    "from util import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "features, labels = data.load_wisconsin_breast_cancer()\n",
    "wbc_X_train, wbc_X_test, wbc_y_train, wbc_y_test = train_test_split(\n",
    "    features, labels, test_size=0.2)\n",
    "# print(features.shape)\n",
    "# print(labels.shape)\n",
    "\n",
    "# print (features[0])\n",
    "# print (labels)\n",
    "\n",
    "M_features, M_labels = data.load_MNIST_13()\n",
    "MNIST_X_train, MNIST_X_test, MNIST_y_train, MNIST_y_test = train_test_split(\n",
    "    M_features, M_labels, test_size = 0.2)\n",
    "\n",
    "# print(M_features.shape)\n",
    "# print(M_labels.shape)\n",
    "\n",
    "# print (M_features[0])\n",
    "# print (M_labels)\n",
    "\n",
    "cod_features, cod_labels = data.load_cod_rna()\n",
    "# print(cod_features.shape)\n",
    "# print(cod_labels.shape)\n",
    "\n",
    "# print(cod_features[0])\n",
    "# print(cod_labels)\n",
    "\n",
    "cod_X_train, cod_X_test, cod_y_train, cod_y_test = train_test_split(\n",
    "    cod_features, cod_labels, test_size = 0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "rel_conv = 0.000001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Learning Rate Objects\n",
    "lr = FixedRate(0.001)\n",
    "\n",
    "lr1 = FixedRate(0.00001)\n",
    "\n",
    "lr2 = FixedRate(0.0001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "fit() got an unexpected keyword argument 'non_zero_init'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-5-34f52d82c7c3>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mmirror\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mMirrorDescent\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[0mmirror_log\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mLogisticRegression\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmirror\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mFixedRate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m0.01\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m10000\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[0mloss\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmirror_log\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mwbc_X_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mwbc_y_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnon_zero_init\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m: fit() got an unexpected keyword argument 'non_zero_init'"
     ]
    }
   ],
   "source": [
    "mirror = MirrorDescent()\n",
    "mirror_log = LogisticRegression(mirror, FixedRate(0.01), 10000, 1)\n",
    "loss = mirror_log.fit(wbc_X_train, wbc_y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Accuracy: 85.71%\n"
     ]
    }
   ],
   "source": [
    "acc = check_accuracy(mirror_log, wbc_X_test, wbc_y_test)\n",
    "print(\"Model Accuracy: {0:.2f}%\".format(acc * 100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Descent Algorithm Objects\n",
    "gd = GradientDescent()\n",
    "gd1 = GradientDescent()\n",
    "gd2 = GradientDescent()\n",
    "# gd = StochasticVarianceReducedGradientDescent()\n",
    "# gd = NesterovAcceleratedDescent()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Models(descent_algo, learning rate, iterations, batch, relative convergence)\n",
    "logreg = LogisticRegression(gd, lr, 25000, wbc_X_train.shape[0], rel_conv)\n",
    "\n",
    "cod_logreg = LogisticRegression(gd1, lr1, 25000, cod_X_train.shape[0], rel_conv)\n",
    "\n",
    "MNIST_logreg = LogisticRegression(gd2, lr2, 2500, MNIST_X_train.shape[0], rel_conv)\n",
    "\n",
    "\n",
    "#Models(descent_algo, learning rate, iterations, batch, relative convergence)\n",
    "# logreg = LogisticRegression(gd, lr, 16000, wbc_X_train.shape[0], rel_conv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss = logreg.fit(wbc_X_train, wbc_y_train)\n",
    "\n",
    "loss_cod = cod_logreg.fit(cod_X_train, cod_y_train)\n",
    "\n",
    "loss_MNIST = MNIST_logreg.fit(MNIST_X_train, MNIST_y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#modelAccuracyCheck\n",
    "acc = check_accuracy(logreg, wbc_X_test, wbc_y_test)\n",
    "print(\"Model Accuracy: {0:.2f}%\".format(acc * 100))\n",
    "\n",
    "acc = check_accuracy(cod_logreg, cod_X_test, cod_y_test)\n",
    "print(\"Model Accuracy: {0:.2f}%\".format(acc * 100))\n",
    "\n",
    "acc = check_accuracy(MNIST_logreg, MNIST_X_test, MNIST_y_test)\n",
    "print(\"Model Accuracy: {0:.2f}%\".format(acc * 100))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "# plt.figure(200)\n",
    "# plt.title('Training Accuracy')\n",
    "# plt.xlabel('Iteration x10^2')\n",
    "# plt.ylabel('Accuracy')\n",
    "# plt.plot(accuracies, 'b')\n",
    "# plt.show()\n",
    "# plt.figure(300)\n",
    "# plt.title('Validation Accuracy')\n",
    "# plt.xlabel('Iteration x10^2')\n",
    "# plt.ylabel('Accuracy')\n",
    "# plt.plot(val_accuracies, 'b')\n",
    "# plt.show()\n",
    "plt.figure(1, figsize=(12, 6))\n",
    "plt.title('Loss Plot')\n",
    "plt.xlabel('Iteration Number')\n",
    "plt.ylabel('Loss')\n",
    "plt.plot(loss, 'b')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
