# mlo_final_project
Final project for Machine Learning: Optimization

## Group Members
Peter Klinkmueller
Archan Patel
Will Ye
Jason Zhang

## Initial Outline
Comparing convergence rate, runtime, and accuracy for
  - Gradient Descent [UNIMPLEMENTED]
  - Nesterov's Accelerated Gradient Descent [UNIMPLEMENTED]
  - Mirror Descent [UNIMPLEMENTED]
  - Stochastic Gradient Descent [UNIMPLEMENTED]
  - Stochastic Variance Reduced Gradient (SVRG) [UNIMPLEMENTED]
  - Katyusha's Algorithm [MAYBE/MAYBE NOT]
  - Coordinate Descent for logistic regression [UNIMPLEMENTED]

with smooth loss functions (recommended: squared loss - as well as one to two others) and L-1 regularization.
